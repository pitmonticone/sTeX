\makeatletter
\ifcsname if@infulldoc\endcsname\else
    \expandafter\newif\csname if@infulldoc\endcsname\@infulldocfalse
\fi
\makeatother

\csname if@infulldoc\endcsname\else

\def\bibfolder{../lib/bib}

\input{stex-docheader}

\infulldoctrue

\begin{document}
  \csname if@infulldoc\endcsname\else
	\title{
		The {\stex{3}} Manual
		\thanks{Version {\fileversion} (last revised {\filedate})}
 	}
	\author{Michael Kohlhase, Dennis Müller\\
		FAU Erlangen-Nürnberg\\
		\url{http://kwarc.info/}
	}
	\pagenumbering{roman}
	\maketitle
	
	\input{stex-abstract}\bigskip

  This is the user manual for the \sTeX package and 
  associated software. It is primarily directed at end-users 
  who want to use \sTeX to author semantically
  enriched documents. For the full documentation, see
  \href{\basedocurl/stex.pdf}{the \sTeX documentation}
	
	\makeatletter
		\renewcommand\part{%
    		\clearpage
  			\thispagestyle{plain}%
  			\@tempswafalse
  			\null\vfil
  			\secdef\@part\@spart%
  		}
		\newcounter{chapter}
		\numberwithin{section}{chapter}
		\renewcommand\thechapter{\@arabic\c@chapter}
		\renewcommand\thesection{\thechapter.\@arabic\c@section}
		\newcommand*\chaptermark[1]{}
		\setcounter{secnumdepth}{2}
		\newcommand\@chapapp{\chaptername}
		%\newcommand\chaptername{Chapter}
  		\def\ps@headings{%
    		\let\@oddfoot\@empty
    		\def\@oddhead{{\slshape\rightmark}\hfil\thepage}%
    		\let\@mkboth\markboth
    		\def\chaptermark##1{%
      			\markright{\MakeUppercase{%
        			\ifnum \c@secnumdepth >\m@ne
            			\@chapapp\ \thechapter. \ %
        			\fi
        		##1}}%
        	}%
        }
		\newcommand\chapter{\clearpage
			\thispagestyle{plain}%
			\global\@topnum\z@
			\@afterindentfalse
			\secdef\@chapter\@schapter%
		}
		\def\@chapter[#1]#2{\refstepcounter{chapter}%
			\typeout{\@chapapp\space\thechapter.}%
			\addcontentsline{toc}{chapter}%
				{\protect\numberline{\thechapter}#1}%
			\chaptermark{#1}%
			\addtocontents{lof}{\protect\addvspace{10\p@}}%
			\addtocontents{lot}{\protect\addvspace{10\p@}}%
			\@makechapterhead{#2}%
			\@afterheading%
		}
		\def\@makechapterhead#1{%
			\vspace*{50\p@}%
			{\parindent \z@ \raggedright \normalfont
				\huge\bfseries \@chapapp\space \thechapter
				\par\nobreak
				\vskip 20\p@
				\interlinepenalty\@M
				\Huge \bfseries #1\par\nobreak
				\vskip 40\p@
			}%
		}
\newcommand*\l@chapter[2]{%
  \ifnum \c@tocdepth >\m@ne
    \addpenalty{-\@highpenalty}%
    \vskip 1.0em \@plus\p@
    \setlength\@tempdima{1.5em}%
    \begingroup
      \parindent \z@ \rightskip \@pnumwidth
      \parfillskip -\@pnumwidth
      \leavevmode \bfseries
      \advance\leftskip\@tempdima
      \hskip -\leftskip
      #1\nobreak\hfil
      \nobreak\hb@xt@\@pnumwidth{\hss #2%
                                 \kern-\p@\kern\p@}\par
      \penalty\@highpenalty
    \endgroup
  \fi}
\renewcommand*\l@section{\@dottedtocline{1}{1.5em}{2.8em}}
\renewcommand*\l@subsection{\@dottedtocline{2}{3.8em}{3.2em}}
\renewcommand*\l@subsubsection{\@dottedtocline{3}{7.0em}{4.1em}}
\def\partname{Part}
\def\toclevel@part{-1}
\def\maketitle{\chapter{\@title}}
\let\thanks\@gobble
\let\DelayPrintIndex\PrintIndex
\let\PrintIndex\@empty
\providecommand*{\hexnum}[1]{\text{\texttt{\char`\"}#1}}
\makeatother

\ExplSyntaxOn
\int_set:Nn \l_document_structure_section_level_int {1}
\ExplSyntaxOff

\clearpage

{%
  \def\\{:}% fix "newlines" in the ToC
  \tableofcontents
}

\clearpage
\pagenumbering{arabic}
	
\fi

\long\def\ignore#1{}


\begin{dangerbox}
  Boxes like this one contain implementation details that are
  mostly relevant for more advanced use cases, might be useful 
  to know when debugging, or might be good to know to better understand
  how something works. They can easiyl be skipped on a first read.
\end{dangerbox}

\begin{mmtbox}
  Boxes like this one explain how some \sTeX concept
  relates to the \mmt/\omdoc system, philosophy or language.
\end{mmtbox}


\begin{sfragment}{What is \sTeX?}
  
Formal systems for mathematics (such as interactive theorem provers)
have the potential to significantly increase both the accessibility
of published knowledge, as well as the confidence in its veracity,
by rendering the precise semantics of statements machine actionable.
This allows for a plurality of added-value services, from semantic
search up to verification and automated theorem proving.
Unfortunately, their usefulness is hidden behind severe barriers
to accessibility; primarily related to their surface languages
reminiscent of programming languages and very unlike informal
standards of presentation.

\sTeX minimizes this gap between informal and formal 
mathematics by integrating formal methods into established
and widespread authoring workflows, primarily \LaTeX, via 
non-intrusive semantic
annotations of arbitrary informal document fragments. That way
formal knowledge management services become available for informal
documents, accessible via an IDE for authors and via generated
\emph{active} documents for readers, while remaining fully compatible
with existing authoring workflows and publishing systems.

Additionally, an extensible library of reusable
document fragments is being developed, that serve as reference targets
for global disambiguation, intermediaries for content exchange
between systems and other services.

Every component of the system is designed modularly and extensibly,
and thus lay the groundwork for a potential full integration of
interactive theorem proving systems into established informal document
authoring workflows.

\paragraph{} The general \sTeX workflow combines functionalities
provided by several pieces of software:
\begin{itemize}
  \item The \sTeX package to use semantic annotations in
    {\LaTeX} documents,
  \item \RusTeX to convert |tex| sources to (semantically enriched)
    |xhtml|,
  \item The \mmt software, that extracts semantic information
    from the thus generated |xhtml| and provides semantically informed
    added value services.
\end{itemize}


% ----------------------------

\ignore{The objectives of this project will be achieved by developing a 
language and system 
that uses non-intrusive annotations
to augment informal documents with semantic information
(ranging from \textbf{fully formal} to \textbf{purely informal})
 without
impacting linguistic presentation or document layout. 
That way, the system
remains compatible with established publishing
pipelines and practices, while additionally providing flexiformal 
information that
enables formal knowledge management services, and hence produces 
\emph{rich active documents}, satisfying \textbf{R3}, \textbf{R4} and 
\textbf{R5}.
In particular, it will avoid commitment to a fixed logical foundation.
Instead, it will be designed as a modular pipeline of consecutive
and compositional
annotations, semantics extraction and translation steps, extensible
via new structuring mechanisms (\textbf{R1}), library content 
(\textbf{R2}),
NLP techniques, foundations, translation methods and 
end-user services.

Naturally, the benefits of formal knowledge management services scale 
with the amount of mathematics involved. Consequently I will primarily 
focus on those 
STEM fields in which mathematical methods are most prominently
used (e.g. mathematics, physics, computer science). Since in those fields
\LaTeX~is the most commonly used scientific writing tool, I will also
primarily focus on \LaTeX~as a development and evaluation target, but 
the system will be designed such that all components apart from
the surface language will be integrable with other writing tools 
(e.g. WYSIWYG word processors).

\paragraph{} The basic architecture of the proposed system is sketched in
\autoref{fig:architecture}.
\begin{figure}\centering
  \resizebox{0.95\textwidth}{!}{\tikzinput[]{diagram}}
  {\small (Note, that the syntax used
    in the box on the top right is prototypical and subject to change during the project.
    Details and open questions regarding the syntax are discussed here:
    \url{https://github.com/KWARC/FoMID/issues/1})}
  \caption{Basic Architecture of the Proposed System}\label{fig:architecture}
\end{figure}
A user can write their content using standard \LaTeX\ in an IDE;
ideally using semantic annotations provided by \sTeX
%and the library developed in \OBJref{smglom}
(as in the upper right of 
\autoref{fig:architecture}), but not necessarily so.

The document is converted to xhtml with \omdoc annotations
using \LaTeX ML in the background,
thus becoming actionable by the \mmt system. Both the source document
as well as the generated xhtml/\omdoc are accessible to a natural language
processing pripeline that can supply additional inferred semantic 
information or suggest annotations to the user, in the latter case 
augmenting the source document directly. This pipeline can use both 
classical NLP techniques using the GLIF system, as well as machine 
learning models such as \cite{own:fifom}.

A semiformal fragment is converted 
into an appropriate syntax tree (possibly containing opaque
informal nodes), 
thus becoming amenable
to flexiformal knowledge management services. In a consecutive step
-- if sufficiently annotated --, these are
additionally translated
to a fully formal foundation, e.g. using the techniques from 
\cite{DMueller:phd:19,own:translations}, allowing
more powerful services and conversion to established formal
systems. All three representations
are thus available from within the \mmt system for various
knowledge management services, interfaces for which can be
implemented in the IDE.

Importantly, every non-trivial arrow in the figure is 
composable and extensible -- 
translations to a foundation can be provided
by supplying an appropriate formalization and alignment-based
translations (or entirely new methods),
services can be implemented generically using the \mmt API,
NLP techniques can be implemented both inside and alongside of
GLIF, and the concrete syntax within \sTeX can be extended
by convenience macros in \LaTeX\ (enabling new
structuring mechanisms as in \textbf{R1} via 
\mmt extensions, see
\cite{MueRabRot:rslffml20}) as well as via additions to
the library, which will be extensible both from within the IDE
as well as on MathHub,
remaining backwards compatible with existing content in a surface 
language. Additionally, sufficiently disambiguated
statements can be translated to the syntax of 
external systems (such as interactive theorem prover systems
or computer algebra systems),
which can thus be integrated as additional services into the system.
}

\end{sfragment}

\begin{sfragment}{Quickstart}

	\begin{sfragment}{Setup}
		\begin{sfragment}{The \sTeX IDE}
      TODO: VSCode Plugin
    \end{sfragment}
    \begin{sfragment}{Manual Setup}
      Foregoing on the \sTeX IDE, we will need several
      pieces of software; namely:
      \begin{itemize}
        \item \textbf{The \sTeX-Package} available 
          \href{https://github.com/slatex/sTeX/blob/latex3/doc/stex.pdf}{here}.

          \sTeX is also available on CTAN and in \TeX Live.

        \item To make sure that \sTeX too knows where to find its
          archives, we need to set a global system variable |MATHHUB|,
          that points to your local |MathHub|-directory 
          (see \sref{sec.stexarchives}).
          %If you are only interested in using semantic macros in (ultimately)
          %|pdf|s generated by |pdflatex|, this is all you need.

        \item \textbf{The \mmt System} available
          \href{https://github.com/uniformal/MMT/tree/sTeX}{here}%
          \ednote{For now, we require the \texttt{sTeX}-branch, requiring manually
          compiling the MMT sources}. We recommend following
          the setup routine documented 
          \href{https://uniformal.github.io//doc/setup/}{here}.

          Following the setup routine (Step 3) will entail designating
          a |MathHub|-directory on your local file system, where
          the \mmt system will look for \sTeX/\mmt content archives.

        \item \textbf{\sTeX Archives} If we only care about {\LaTeX} and generating |pdf|s, we do not
          technically need \mmt at all; however, we still need the |MATHHUB|
          system variable to be set. Furthermore, \mmt can make downloading
          content archives we might want to use significantly easier, since
          it makes sure that all dependencies of (often highly interrelated)
          \sTeX archives are cloned as well.

          Once set up, we can run |mmt| in a shell and download an archive along with
          all of its dependencies like this: |lmh install <name-of-repository>|,
          or a whole \emph{group} of archives; for example,
          |lmh install smglom| will download all smglom archives.
        \item \textbf{\RusTeX} The \mmt system will also set up \RusTeX for you,
          which is used to generate (semantically annotated)
          |xhtml| from tex sources. In lieu of using \mmt, you
          can also download and use \RusTeX directly
          \href{https://github.com/slatex/RusTeX}{here}.

      \end{itemize}
    \end{sfragment}
	\end{sfragment}

  \input{stex-tutorial}

\end{sfragment}

\begin{sfragment}{Creating \sTeX Content}

  \input{packages/stex-basics}

  \begin{sfragment}{How Knowledge is Organized in \sTeX}

    \sTeX content is organized on multiple levels:
    \begin{itemize}
      \item \sTeX \textbf{archives} (see \sref{sec.stexarchives})
        contain individual |.tex|-files.
      \item These may contain \sTeX \textbf{modules}, introduced via 
      \stexcode"\begin{smodule}{ModuleName}".\iffalse\end{smodule}\fi
      \item Modules contain \sTeX \textbf{symbol declarations}, introduced via
        \stexcode"\symdecl{symbolname}", \stexcode"\symdef{symbolname}" and some other
        constructions. Most symbols have a \emph{notation} that can
        be used via a \emph{semantic macro} \stexcode"\symbolname" generated
        by symbol declarations.
      \item \sTeX \textbf{expressions} finally are built up from
        usages of semantic macros.
    \end{itemize}

    \begin{mmtbox}
      \begin{itemize}
        \item \sTeX archives are simultaneously \mmt archives, and the same
          directory structure is consequently used.
        \item \sTeX modules correspond to \omdoc/\mmt \emph{theories}.
          \stexcode"\importmodule"s (and similar constructions) induce 
          \mmt |include|s and other \emph{theory morphisms},
          thus giving rise to a \emph{theory graph} in the \omdoc sense.
        \item Symbol declarations induce \omdoc/\mmt \emph{constants},
          with optional (formal) \emph{type} and \emph{definiens} components.
        \item Finally, \sTeX expressions are converted to \omdoc/\mmt terms,
          which use the syntax of \openmath.
      \end{itemize}
    \end{mmtbox}

	\end{sfragment}

  \begin{sfragment}[id=sec.stexarchives]{\sTeX Archives}
    \input{packages/stex-mathhub}
  \end{sfragment}

  \begin{sfragment}[id=sec.decls]{Module, Symbol and Notation Declarations}
    \input{packages/stex-modules}

    \input{packages/stex-symbols}
  \end{sfragment}

  \begin{sfragment}{Module Inheritance and Structures}

    \begin{sfragment}{Multilinguality and Translations}

      If we load the \sTeX document class or package with the option
      |lang=<lang>|, \sTeX will load the appropriate \pkg{babel}
      language for you -- e.g. |lang=de| will load the babel
      language |ngerman|. Additionally, it makes \sTeX aware
      of the current document being set in (in this example)
      \emph{german}. This matters for reasons other than mere
      \pkg{babel}-purposes, though:

      Every \emph{module} is assigned a language. If no \sTeX
      package option is set that allows for inferring a language,
      \sTeX will check whether the current file name ends in
      e.g. |.en.tex| (or |.de.tex| or |.fr.tex|, or...) and
      set the language accordingly. Alternatively, a language
      can be explicitly assigned via 
      \stexcode"\begin{smodule}[lang=<language>]{Foo}".
      \iffalse\end{smodule}\fi

      \begin{mmtbox}
        Technically, each |smodule|-environment induces \emph{two}
        \omdoc/\mmt theories:
        \stexcode"\begin{smodule}[lang=<lang>]{Foo}"
        \iffalse\end{smodule}\fi
        generates a theory |some/namespace?Foo| that only contains
        the ``formal'' part of the module -- i.e. exactly the
        content that is exported when using \stexcode"\importmodule".

        Additionally, \mmt generates a \emph{language theory} 
        |some/namespace/Foo?<lang>| that includes |some/namespace?Foo|
        and contains all the other document content -- variable
        declarations, includes for each \stexcode"\usemodule", etc.
      \end{mmtbox}

      Notably, the language suffix in a filename is ignored
      for \stexcode"\usemodule", \stexcode"\importmodule"
      and in generating/computing URIs for modules. This however
      allows for providing \emph{translations} for modules
      between languages without needing to duplicate content:

      If a module |Foo| exists in e.g. english in a file |Foo.en.tex|,
      we can provide a file |Foo.de.tex| right next to it, and write
      \stexcode"\begin{smodule}[sig=en]{Foo}".
      \iffalse\end{smodule}\fi
      The |sig|-key then signifies, that the ``signature'' of the
      module is contained in the \emph{english} version of the module,
      which is immediately imported from there, just like
      \stexcode"\importmodule" would.

      Additionally to translating the informal content of a module
      file to different languages, it also allows for customizing
      notations between languages. For example,
      the \emph{least common multiple} of two numbers is often
      denoted as $\mathtt{lcm}(a,b)$ in english, but is
      called \emph{kleinstes gemeinsames Vielfaches} in german
      and consequently denoted as $\mathtt{kgV}(a,b)$ there.

      We can therefore imagine a german version of an lcm-module
      looking something like this:

      \begin{latexcode}[gobble=8]
        \begin{smodule}[sig=en]{lcm}
          \notation*{lcm}[de]{\comp{\mathtt{kgV}}(#1,#2)}

          Das \symref{lcm}{kleinste gemeinsame Vielfache}
          $\lcm{a,b}$ von zwei Zahlen $a,b$ ist... 
        \end{smodule}
      \end{latexcode}

      If we now do \stexcode"\importmodule{lcm}"
      (or \stexcode"\usemodule{lcm}") within a \emph{german} document,
      it will also load the content of the german translation,
      including the |de|-notation for \stexcode"\lcm".

    \end{sfragment}

    \input{packages/stex-inheritance}
    \input{packages/stex-features}
  \end{sfragment}

  \begin{sfragment}{Primitive Symbols (The \sTeX Metatheory)}
    \input{packages/stex-metatheory}
  \end{sfragment}
  
\end{sfragment}

\begin{sfragment}[id=sec.textsymbols]{Using \sTeX Symbols}
  \input{packages/stex-terms}

  \input{packages/stex-references}

\end{sfragment}

\begin{sfragment}{\sTeX Statements}
  \input{packages/stex-statements}

  \input{packages/stex-proofs}
\end{sfragment}

\begin{sfragment}[id=sec.customhighlight]{Highlighting and Presentation Customizations}

\end{sfragment}

\begin{sfragment}{Additional Packages}
  \input{packages/stex-tikzinput}
  \begin{sfragment}{Modular Document Structuring}
    \input{packages/stex-document-structure}
  \end{sfragment}
  \begin{sfragment}{Slides and Course Notes}
    \input{packages/stex-slides}
  \end{sfragment}
  \begin{sfragment}{Homework, Problems and Exams}
    \input{packages/stex-problem}
    
    \input{packages/stex-hwexam}
  \end{sfragment}

\end{sfragment}
	
\csname if@infulldoc\endcsname\else\end{document}\fi
